import os
import yaml
import hashlib
import subprocess
import logging
import shutil
import re
import ipaddress
import json
from datetime import datetime, timedelta, timezone
from collections import defaultdict

# --- å…¨å±€é…ç½® ---
SOURCE_DIR = "temp_source/rule/Clash"
TARGET_DIR_MIHOMO = "rule/Mihomo"
TARGET_DIR_LOON = "rule/Loon"
HISTORY_FILE = "history.json"
README_FILE = "README.md"
MIHOMO_BIN = "./mihomo"

# ğŸ›‘ å˜ä½“å‰”é™¤é»‘åå•: åŒ…å«è¿™äº›å…³é”®è¯çš„æ–‡ä»¶å°†è¢«å¿½ç•¥ï¼Œåªå¤„ç†ä¸»æ–‡ä»¶
IGNORE_KEYWORDS = ["Classical", "Domain", "For_Clash", "No_Resolve", "Clash"]

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("DigitalArchitect")

filename_registry = {}

# --- åŠ¨æ€å…ƒæ•°æ®è·å– ---
def get_metadata():
    # æ ¼å¼: Owner/Repo (ä¾‹å¦‚ Keviin560/Shunt_Rules)
    repo_full = os.getenv('GITHUB_REPOSITORY')
    
    if repo_full and "/" in repo_full:
        author = repo_full.split("/")[0]
        # RAW é“¾æ¥çš„åŸºç¡€è·¯å¾„
        raw_base = f"https://raw.githubusercontent.com/{repo_full}/main"
        repo_url = f"https://github.com/{repo_full}"
    else:
        # æœ¬åœ°æµ‹è¯•å…œåº•
        author = "Unknown"
        raw_base = "https://raw.githubusercontent.com/Unknown/Test/main"
        repo_url = "https://github.com/Unknown/Test"
        repo_full = "YourName/RepoName" # ç”¨äºæ–‡æ¡£å±•ç¤º
        
    return author, raw_base, repo_url, repo_full

AUTHOR_NAME, RAW_BASE_URL, REPO_URL, REPO_NAME_DISPLAY = get_metadata()

# --- æ ¸å¿ƒç»„ä»¶ ---
class KernelIntrospector:
    """å†…æ ¸å†…çœå™¨ï¼šæ¢æµ‹å‚æ•°æ ¼å¼ï¼Œé˜²æ­¢å› å†…æ ¸æ›´æ–°å¯¼è‡´çš„å‚æ•°é”™è¯¯"""
    def __init__(self, bin_path):
        self.bin_path = bin_path
        if not os.path.exists(bin_path): raise FileNotFoundError(f"å†…æ ¸ç¼ºå¤±: {bin_path}")
        self.needs_format_arg = self._detect()

    def _detect(self):
        try:
            res = subprocess.run([self.bin_path, "convert-ruleset"], capture_output=True, text=True, timeout=5)
            out = res.stderr + res.stdout
            return "<format>" in out or " [format] " in out
        except: return False

    def get_cmd(self, behavior, src, dst):
        cmd = [self.bin_path, "convert-ruleset", behavior]
        if self.needs_format_arg: cmd.append("yaml")
        cmd.append(src)
        cmd.append(dst)
        return cmd

class RuleSet:
    def __init__(self):
        # å­˜å‚¨: set( (type, value) )
        self.domain_entries = set()
        # å­˜å‚¨: dict( ip_str -> is_no_resolve )
        self.ip_entries = defaultdict(bool)

    def add_domain(self, line):
        line = line.strip().strip("'").strip('"')
        if not line or line.startswith('#'): return
        
        rule_type = "DOMAIN-SUFFIX"
        value = line
        
        # å¤„ç† DOMAIN,google.com æ ¼å¼
        if ',' in line:
            parts = line.split(',')
            if len(parts) >= 2:
                t, v = parts[0].upper().strip(), parts[1].strip()
                if 'DOMAIN' in t: rule_type, value = t, v
        
        if len(value) > 3: 
            self.domain_entries.add((rule_type, value))

    def add_ip(self, line):
        if not line: return
        clean = line.replace("'", "").replace('"', "").strip()
        parts = re.split(r'[,\s]+', clean)
        
        target = None
        no_res = False
        
        for p in parts:
            p = p.strip()
            # è¿‡æ»¤éæ•°æ®éƒ¨åˆ†
            if not p or 'IP-' in p.upper(): continue
            if p.lower() == 'no-resolve': 
                no_res = True
                continue
            
            # [ç‰©ç†éš”ç¦»] ä½¿ç”¨ ipaddress åº“å¼ºæ ¡éªŒï¼Œé IP ç›´æ¥ä¸¢å¼ƒ
            try:
                ipaddress.ip_network(p, strict=False)
                target = p
            except ValueError: continue
            
        if target:
            if not self.ip_entries[target]: 
                self.ip_entries[target] = no_res

class HistoryManager:
    """å†å²è®°å½•ç®¡ç†å™¨ï¼šè¿½è¸ªæ–‡ä»¶æ›´æ–°çŠ¶æ€"""
    def __init__(self):
        self.history = {}
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, 'r') as f: self.history = json.load(f)
            except: pass
        self.current_time = int(datetime.now().timestamp())

    def get_file_hash(self, filepath):
        if not os.path.exists(filepath): return ""
        with open(filepath, 'rb') as f: return hashlib.md5(f.read()).hexdigest()

    def update_record(self, name, filepath):
        current_hash = self.get_file_hash(filepath)
        record = self.history.get(name, {})
        last_hash = record.get('hash', "")
        last_ts = record.get('time', self.current_time)

        if current_hash != last_hash:
            self.history[name] = {'hash': current_hash, 'time': self.current_time}
            return 0 # Today
        else:
            diff = datetime.fromtimestamp(self.current_time) - datetime.fromtimestamp(last_ts)
            return diff.days

    def save(self):
        with open(HISTORY_FILE, 'w') as f: json.dump(self.history, f, indent=2)

# --- æ–‡ä»¶å¤„ç† ---
def get_smart_filename(rel_path):
    parts = rel_path.split(os.sep)
    base = os.path.splitext(parts[-1])[0]
    cand = base
    stack = parts[:-1]
    while cand in filename_registry:
        if filename_registry[cand] == rel_path: return cand
        if not stack:
            cand = f"{cand}_{hashlib.md5(rel_path.encode()).hexdigest()[:4]}"
            break
        cand = f"{stack.pop()}_{cand}"
    filename_registry[cand] = rel_path
    return cand

def should_skip(fname):
    base = os.path.splitext(fname)[0]
    for k in IGNORE_KEYWORDS:
        if k in base: return True
    return False

def parse_file(path, ruleset):
    try:
        with open(path, 'r', encoding='utf-8', errors='ignore') as f:
            if path.endswith(('.yaml', '.yml')):
                try:
                    data = yaml.safe_load(f)
                    if data and 'payload' in data:
                        for l in data['payload']: process_entry(str(l), ruleset)
                except: pass
            else:
                for l in f: process_entry(l, ruleset)
    except: pass

def process_entry(line, ruleset):
    line = line.strip()
    if not line or line.startswith('#'): return
    if line.startswith("['"): line = line.replace('[','').replace(']','').replace("'", "")
    
    upper = line.upper()
    if 'DOMAIN' in upper or (not 'IP-' in upper and '.' in line and not line[0].isdigit()):
        ruleset.add_domain(line)
    else:
        ruleset.add_ip(line)

def verify_artifact(filepath):
    if not os.path.exists(filepath): return False
    if os.path.getsize(filepath) == 0: return False
    return True

# --- Mihomo æ„å»º ---
def build_mihomo(kernel, name, ruleset):
    has_d, has_i = False, False
    if ruleset.domain_entries:
        clean = sorted(list(set([v for t,v in ruleset.domain_entries])))
        if _compile_mihomo(kernel, name, clean, 'domain'): has_d = True
            
    if ruleset.ip_entries:
        # âš ï¸ å…³é”®ï¼šMihomo ä¸æ”¯æŒ no-resolve åç¼€ï¼Œåªæå–çº¯ IP
        clean = sorted(ruleset.ip_entries.keys())
        if _compile_mihomo(kernel, f"{name}_IP", clean, 'ipcidr'): has_i = True
            
    return has_d, has_i

def _compile_mihomo(kernel, name, rules, behavior):
    tmp = f"temp_{name}.yaml"
    dst = os.path.join(TARGET_DIR_MIHOMO, f"{name}.mrs")
    try:
        with open(tmp, 'w', encoding='utf-8') as f: yaml.dump({'payload': rules}, f)
        res = subprocess.run(kernel.get_cmd(behavior, tmp, dst), capture_output=True, text=True, timeout=20)
        
        # é”™è¯¯å®¹å¿ï¼šå¿½ç•¥ unknown field è­¦å‘Š
        if res.returncode != 0 and "unknown field" not in res.stderr:
             # logger.error(f"âŒ Mihomo è½¬æ¢å¤±è´¥ [{name}]: {res.stderr.strip()}") 
             # ä¿æŒå®‰é™ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æœ‰å¼ºæ ¡éªŒï¼Œè¿™é‡Œçš„æŠ¥é”™é€šå¸¸æ˜¯æå°‘æ•°çš„è„æ•°æ®ï¼Œä¸å½±å“å¤§å±€
             if os.path.exists(dst): os.remove(dst)
             return False
             
        if not verify_artifact(dst):
            if os.path.exists(dst): os.remove(dst)
            return False
        return True
    except: return False
    finally:
        if os.path.exists(tmp): os.remove(tmp)

# --- Loon æ„å»º ---
def get_loon_priority(line):
    # äº”å±‚æ¼æ–—æ’åº
    if line.startswith("IP-CIDR") and "no-resolve" in line: return 0
    if line.startswith("DOMAIN,"): return 10
    if line.startswith("DOMAIN-SUFFIX"): return 20
    if "KEYWORD" in line or "REGEX" in line: return 30
    if line.startswith("IP-CIDR"): return 99
    return 50

def build_loon(name, ruleset):
    count = len(ruleset.domain_entries) + len(ruleset.ip_entries)
    if count == 0: return False
    
    dst = os.path.join(TARGET_DIR_LOON, f"{name}.lsr")
    lines = []
    
    # ç»§æ‰¿ no-resolve å±æ€§
    for ip, no_res in ruleset.ip_entries.items():
        suffix = ",no-resolve" if no_res else ""
        lines.append(f"IP-CIDR,{ip}{suffix}")
        
    for t, v in ruleset.domain_entries:
        lines.append(f"{t},{v}")
        
    lines.sort()
    lines.sort(key=get_loon_priority)
    
    bj_time = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M:%S')
    try:
        with open(dst, 'w', encoding='utf-8') as f:
            f.write(f"# Name = {name}\n# Author = {AUTHOR_NAME}\n# REPO = {REPO_URL}\n# Update = {bj_time}\n# Total = {count}\n\n")
            f.write("\n".join(lines))
        return True
    except: return False

# --- README ç”Ÿæˆ ---
def generate_readme(stats):
    stats.sort(key=lambda x: x[0])
    total = len(stats)
    bj_time = (datetime.now(timezone.utc) + timedelta(hours=8)).strftime('%Y-%m-%d %H:%M')
    
    md = [
        f"# ğŸš€ Shunt Rules è§„åˆ™é›†ä»“åº“",
        f"![Total](https://img.shields.io/badge/è§„åˆ™æ€»æ•°-{total}-blue) ![Update](https://img.shields.io/badge/æ›´æ–°æ—¶é—´-{bj_time.replace(' ', '_')}-green)",
        f"",
        f"## â„¹ï¸ æ•°æ®æºè¯´æ˜",
        f"æœ¬ä»“åº“è§„åˆ™æ•°æ®åŒæ­¥è‡ª [blackmatrix7/ios_rule_script](https://github.com/blackmatrix7/ios_rule_script) é¡¹ç›®ï¼Œæ„Ÿè°¢å„ä½ç»´æŠ¤è§„åˆ™çš„å¤§ä½¬ä»¬ã€‚",
        f"",
        f"## âš ï¸ ä½¿ç”¨å‰å¿…è¯»",
        f"* **Mihomo**: `.mrs` ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œä¸æ”¯æŒç›´æ¥ç¼–è¾‘ã€‚`_IP.mrs` å·²**ç§»é™¤** `no-resolve` å±æ€§ä»¥é˜²æ­¢å†…æ ¸å´©æºƒï¼Œ**å¿…é¡»**åœ¨é…ç½®æ–‡ä»¶ä¸­è‡ªè¡ŒæŒ‡å®šç­–ç•¥ã€‚",
        f"* **Loon**: `.lsr` æ”¯æŒæ··åˆè´Ÿè½½ï¼Œå·²å†…ç½®ä¼˜åŒ–æ’åºï¼ˆno-resolve IP ä¼˜å…ˆï¼‰ã€‚",
        f"",
        f"## ğŸ“ Mihomo é…ç½®æŒ‡å¼•",
        f"å»ºè®®ä½¿ç”¨ `type: http` è¿œç¨‹å¼•ç”¨è§„åˆ™é›†ã€‚ä»¥ä¸‹ä»£ç ä»¥ **Google** è§„åˆ™ä¸ºä¾‹ï¼Œè¯·æ ¹æ®å®é™…éœ€æ±‚ä¿®æ”¹ç­–ç•¥ç»„åç§°ã€‚",
        f"",
        f"**1. å®šä¹‰ç­–ç•¥ç»„ (Proxy Groups)**",
        f"```yaml",
        f"proxy-groups:",
        f"  - name: \"MyProxyGroup\"   # ç­–ç•¥ç»„åç§°ï¼Œå¯è‡ªå®šä¹‰",
        f"    type: select",
        f"    proxies:",
        f"      - ğŸ‡­ğŸ‡° é¦™æ¸¯èŠ‚ç‚¹      # ğŸ‘ˆ è¿™é‡Œå¡«å†™ä½ åœ¨ 'proxies' ä¸­å®šä¹‰çš„èŠ‚ç‚¹åç§°",
        f"      - ğŸ‡ºğŸ‡¸ ç¾å›½èŠ‚ç‚¹      # ğŸ‘ˆ æˆ–è€…å¡«å†™ 'DIRECT' (ç›´è¿) / 'REJECT' (æ‹’ç»)",
        f"```",
        f"",
        f"**2. é…ç½®è§„åˆ™é›† (Rule Providers)**",
        f"```yaml",
        f"rule-providers:",
        f"  # ğŸŸ¢ æ¡ˆä¾‹ 1ï¼šå¼•ç”¨åŸŸåè§„åˆ™ (behavior: domain)",
        f"  Google:",
        f"    type: http",
        f"    behavior: domain",
        f"    format: mrs",
        f"    url: \"{RAW_BASE_URL}/{TARGET_DIR_MIHOMO}/Google.mrs\"",
        f"    path: ./rules/Mihomo/Google.mrs",
        f"    interval: 86400",
        f"",
        f"  # ğŸŸ¢ æ¡ˆä¾‹ 2ï¼šå¼•ç”¨ IP è§„åˆ™ (behavior: ipcidr)",
        f"  Google_IP:",
        f"    type: http",
        f"    behavior: ipcidr",
        f"    format: mrs",
        f"    url: \"{RAW_BASE_URL}/{TARGET_DIR_MIHOMO}/Google_IP.mrs\"",
        f"    path: ./rules/Mihomo/Google_IP.mrs",
        f"    interval: 86400",
        f"```",
        f"",
        f"**3. åº”ç”¨è§„åˆ™ (Rules)**",
        f"*âš ï¸ å…³é”®ï¼šå¼•ç”¨ IP è§„åˆ™é›†æ—¶ï¼Œè¯·åŠ¡å¿…åŠ ä¸Š `no-resolve`ï¼Œé˜²æ­¢ DNS æ³„éœ²ã€‚*",
        f"```yaml",
        f"rules:",
        f"  - RULE-SET,Google,MyProxyGroup",
        f"  - RULE-SET,Google_IP,MyProxyGroup,no-resolve",
        f"```",
        f"",
        f"## ğŸ“Š è§„åˆ™ç´¢å¼•",
        f"| è§„åˆ™åç§° | Mihomo (.mrs) | Loon (.lsr) | æ›´æ–°çŠ¶æ€ |",
        f"| :--- | :--- | :--- | :--- |"
    ]
    
    for name, status, has_d, has_i, has_l in stats:
        mihomo_links = []
        if has_d:
            url = f"{RAW_BASE_URL}/{TARGET_DIR_MIHOMO}/{name}.mrs"
            mihomo_links.append(f"[`DOMAIN`]({url})")
        if has_i:
            url = f"{RAW_BASE_URL}/{TARGET_DIR_MIHOMO}/{name}_IP.mrs"
            mihomo_links.append(f"[`IP-CIDR`]({url})")
        mihomo_cell = " \\| ".join(mihomo_links) if mihomo_links else "-"
        
        if has_l:
            url = f"{RAW_BASE_URL}/{TARGET_DIR_LOON}/{name}.lsr"
            loon_cell = f"[`RAW Link`]({url})"
        else:
            loon_cell = "-"
            
        md.append(f"| **{name}** | {mihomo_cell} | {loon_cell} | {status} |")
        
    with open(README_FILE, 'w', encoding='utf-8') as f:
        f.write("\n".join(md))

def get_status_text(days):
    if days == 0: return "Today"
    if days == 1: return "Yesterday"
    return f"{days} days ago"

def main():
    for d in [TARGET_DIR_MIHOMO, TARGET_DIR_LOON]:
        if os.path.exists(d): 
            try: shutil.rmtree(d) 
            except: pass
        os.makedirs(d, exist_ok=True)
    
    if not os.path.exists(SOURCE_DIR): return

    kernel = KernelIntrospector(MIHOMO_BIN)
    history = HistoryManager()
    aggregated = defaultdict(RuleSet)
    
    logger.info("ğŸ” æ‰«æä¸­...")
    cnt, skip = 0, 0
    for root, _, files in os.walk(SOURCE_DIR):
        rel = os.path.relpath(root, SOURCE_DIR)
        if rel == '.': continue
        current = aggregated[rel]
        for f in files:
            if not f.lower().endswith(('.yaml','.yml','.list','.txt')): continue
            if should_skip(f): 
                skip += 1
                continue
            parse_file(os.path.join(root, f), current)
            cnt += 1
            if cnt % 500 == 0: logger.info(f"â³ è§£æ: {cnt} (è·³è¿‡: {skip})...")

    logger.info(f"âœ… è§£æå®Œæ¯•ã€‚è§„åˆ™ç»„: {len(aggregated)}")
    
    stats = []
    done = 0
    for rel, rs in aggregated.items():
        name = get_smart_filename(rel)
        h_d, h_i = build_mihomo(kernel, name, rs)
        h_l = build_loon(name, rs)
        
        if h_d or h_i or h_l:
            # ä½¿ç”¨ Loon æ–‡ä»¶ä½œä¸ºæ›´æ–°æŒ‡çº¹
            check_file = ""
            if h_l: check_file = os.path.join(TARGET_DIR_LOON, f"{name}.lsr")
            elif h_d: check_file = os.path.join(TARGET_DIR_MIHOMO, f"{name}.mrs")
            elif h_i: check_file = os.path.join(TARGET_DIR_MIHOMO, f"{name}_IP.mrs")
            
            days = history.update_record(name, check_file)
            stats.append((name, get_status_text(days), h_d, h_i, h_l))
        
        done += 1
        if done % 100 == 0: logger.info(f"ğŸš€ è¿›åº¦: {done}/{len(aggregated)}")

    history.save()
    generate_readme(stats)
    logger.info("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    main()
