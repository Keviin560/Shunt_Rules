import os
import yaml
import hashlib
import subprocess
import logging
import re
from collections import defaultdict

# --- å…¨å±€é…ç½® ---
SOURCE_DIR = "temp_source/rule/Clash"
TARGET_DIR = "rule/Mihomo"
MIHOMO_BIN = "./mihomo"

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("DigitalArchitect")

filename_registry = {}

class KernelIntrospector:
    """å†…æ ¸å†…çœå™¨ï¼šæ¢æµ‹å‚æ•°æ ¼å¼"""
    def __init__(self, bin_path):
        self.bin_path = bin_path
        if not os.path.exists(bin_path):
            raise FileNotFoundError(f"å†…æ ¸æ–‡ä»¶ä¸å­˜åœ¨: {bin_path}")
        self.needs_format_arg = self._detect_capability()

    def _detect_capability(self):
        try:
            result = subprocess.run([self.bin_path, "convert-ruleset"], capture_output=True, text=True, timeout=5)
            output = result.stderr + result.stdout
            if "<format>" in output or " [format] " in output:
                return True
            return False
        except:
            return False

    def get_cmd(self, behavior, temp_file, output_file):
        cmd = [self.bin_path, "convert-ruleset", behavior]
        if self.needs_format_arg:
            cmd.append("yaml")
        cmd.append(temp_file)
        cmd.append(output_file)
        return cmd

class RuleSet:
    def __init__(self):
        self.domains = set()
        self.ips = defaultdict(bool) 

    def add_domain(self, domain):
        if not domain: return
        # ğŸ§ª æ— èŒæ¸…æ´—ï¼šç§»é™¤å¼•å·ã€ç©ºç™½ã€ä¸å¯è§å­—ç¬¦
        d = domain.strip().strip("'").strip('"').strip()
        if d and not d.startswith('#'):
            self.domains.add(d)

    def add_ip(self, ip_line):
        if not ip_line: return
        # ğŸ§ª æ— èŒæ¸…æ´—ï¼šç§»é™¤å¼•å·
        clean_line = ip_line.replace("'", "").replace('"', "").strip()
        parts = [p.strip() for p in clean_line.split(',')]
        if not parts: return
        
        ip = parts[0]
        if not self._is_valid_cidr(ip): return

        has_no_resolve = 'no-resolve' in parts
        if not self.ips[ip]: 
            self.ips[ip] = has_no_resolve

    def _is_valid_cidr(self, text):
        if not isinstance(text, str): return False
        if not text or not any(char.isdigit() for char in text): return False
        # ä¸¥æ ¼ç™½åå•
        allowed = set("0123456789./:abcdefABCDEF")
        return all(c in allowed for c in text)

def get_smart_filename(source_rel_path):
    parts = source_rel_path.split(os.sep)
    base_name = parts[-1]
    candidate = base_name
    stack = parts[:-1]
    while candidate in filename_registry:
        if filename_registry[candidate] == source_rel_path: return candidate
        if not stack:
            candidate = f"{candidate}_{hashlib.md5(source_rel_path.encode()).hexdigest()[:4]}"
            break
        parent = stack.pop()
        candidate = f"{parent}_{candidate}"
    filename_registry[candidate] = source_rel_path
    return candidate

def parse_file(filepath, ruleset):
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            if filepath.endswith(('.yaml', '.yml')):
                try:
                    data = yaml.safe_load(f)
                    if data and 'payload' in data and isinstance(data['payload'], list):
                        for line in data['payload']: _process_entry(line, ruleset)
                except: pass
            else:
                for line in f: _process_entry(line, ruleset)
    except Exception as e:
        logger.error(f"âŒ è¯»å–é”™è¯¯ {filepath}: {e}")

def _process_entry(line, ruleset):
    """ç»Ÿä¸€å…¥å£å¤„ç†ï¼Œé€’å½’è§£åŒ…"""
    if not line: return
    if isinstance(line, (list, tuple)):
        for item in line: _process_entry(item, ruleset)
        return
    
    line = str(line).strip()
    if not line or line.startswith('#'): return
    
    # å¤„ç† ['IP-CIDR', '...'] è¿™ç§ç•¸å½¢å­—ç¬¦ä¸²
    if line.startswith("['") or line.startswith('["'):
        line = line.replace('[', '').replace(']', '').replace("'", "").replace('"', "")
    
    parts = line.split(',') if ',' in line else line.split()
    parts = [p.strip() for p in parts if p.strip()]
    
    if not parts: return

    type_upper = parts[0].upper()
    if type_upper.startswith('DOMAIN'):
        if len(parts) >= 2: ruleset.add_domain(parts[1])
        elif len(parts) == 1 and '.' in parts[0]: ruleset.add_domain(parts[0])
    elif type_upper.startswith('IP-') or ruleset._is_valid_cidr(parts[0]):
        if type_upper.startswith('IP-') and len(parts) >= 2:
            ip = parts[1]
            extra = parts[2:]
        else:
            ip = parts[0]
            extra = parts[1:]
        
        full = ip
        if 'no-resolve' in extra or 'no-resolve' in line: full += ",no-resolve"
        ruleset.add_ip(full)

def verify_mrs(filepath, behavior):
    """
    ğŸ›¡ï¸ [è´¨æ£€ä»ª] æ ¡éªŒç”Ÿæˆçš„ MRS æ–‡ä»¶æ˜¯å¦åˆæ³•
    """
    if not os.path.exists(filepath):
        return False
    
    # 1. æ£€æŸ¥å¤§å°ï¼šMRS æœ‰å¤´éƒ¨ä¿¡æ¯ï¼Œå¦‚æœæ˜¯ 0 å­—èŠ‚æˆ–æå°ï¼Œè¯´æ˜ç”Ÿæˆå¤±è´¥
    size = os.path.getsize(filepath)
    if size < 20: # ç»éªŒå€¼ï¼ŒMRS å¤´éƒ¨è‡³å°‘æœ‰ Magic Bytes
        logger.error(f"ğŸ—‘ï¸ æ ¡éªŒå¤±è´¥: æ–‡ä»¶è¿‡å° ({size} bytes) -> {filepath}")
        return False
        
    return True

def convert_to_mrs(kernel, name, rules, behavior):
    if not rules: return
    
    temp_yaml = f"temp_{name}.yaml"
    output_mrs = os.path.join(TARGET_DIR, f"{name}.mrs")
    os.makedirs(os.path.dirname(output_mrs), exist_ok=True)
    
    # å†æ¬¡æ¸…æ´—ï¼šç¡®ä¿æ²¡æœ‰ç©ºå­—ç¬¦ä¸²è¿›å…¥åˆ—è¡¨
    clean_rules = [r for r in rules if r and r.strip()]
    if not clean_rules: return

    try:
        with open(temp_yaml, 'w', encoding='utf-8') as f:
            yaml.dump({'payload': clean_rules}, f)
        
        cmd = kernel.get_cmd(behavior, temp_yaml, output_mrs)
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=20)
        
        if result.returncode != 0:
            # ä¸¥é‡é”™è¯¯ï¼Œåˆ é™¤å¯èƒ½äº§ç”Ÿçš„åŠæˆå“
            if os.path.exists(output_mrs): os.remove(output_mrs)
            if "unknown field" not in result.stderr:
                logger.error(f"âŒ è½¬æ¢å´©æºƒ [{name}]: {result.stderr.strip()}")
        else:
            # âœ… è½¬æ¢åç«‹å³è´¨æ£€
            if not verify_mrs(output_mrs, behavior):
                if os.path.exists(output_mrs): os.remove(output_mrs)
            
    except Exception as e:
        logger.error(f"ğŸ’¥ å¼‚å¸¸ [{name}]: {e}")
        if os.path.exists(output_mrs): os.remove(output_mrs)
    finally:
        if os.path.exists(temp_yaml): os.remove(temp_yaml)

def main():
    if os.path.exists(TARGET_DIR): shutil.rmtree(TARGET_DIR) # å…ˆæ¸…ç©ºæ—§çš„ï¼Œç¡®ä¿å…¨æ˜¯æ–°çš„
    os.makedirs(TARGET_DIR)
    
    kernel = KernelIntrospector(MIHOMO_BIN)
    aggregated_rules = defaultdict(RuleSet)
    
    logger.info("ğŸ” å¯åŠ¨...")
    file_count = 0
    for root, dirs, files in os.walk(SOURCE_DIR):
        rel_path = os.path.relpath(root, SOURCE_DIR)
        if rel_path == '.': continue
        current_set = aggregated_rules[rel_path]
        for file in files:
            if file.lower().endswith(('.yaml', '.yml', '.list', '.txt')):
                parse_file(os.path.join(root, file), current_set)
                file_count += 1
                if file_count % 500 == 0: logger.info(f"â³ å·²è§£æ {file_count}...")

    logger.info(f"âš¡ å¼€å§‹ç¼–è¯‘ {len(aggregated_rules)} ä¸ªè§„åˆ™é›†...")
    
    compile_count = 0
    for rel_path, ruleset in aggregated_rules.items():
        safe_name = get_smart_filename(rel_path)
        
        if ruleset.domains:
            convert_to_mrs(kernel, safe_name, sorted(list(ruleset.domains)), 'domain')
            
        if ruleset.ips:
            sorted_ips = sorted(ruleset.ips.items(), key=lambda x: (not x[1], x[0]))
            # å…³é”®ä¿®æ­£ï¼šä¸è¦åœ¨è¿™é‡Œæ‰‹åŠ¨åŠ å¼•å·ï¼Œè®© clean_rules å¤„ç†
            payload = [f"{ip},no-resolve" if no_res else ip for ip, no_res in sorted_ips]
            convert_to_mrs(kernel, f"{safe_name}_IP", payload, 'ipcidr')
        
        compile_count += 1
        if compile_count % 100 == 0: logger.info(f"ğŸš€ è¿›åº¦: {compile_count}/{len(aggregated_rules)}")

    logger.info("ğŸ‰ å®Œæˆ")

if __name__ == "__main__":
    main()
